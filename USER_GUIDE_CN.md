# AiReader 用户指南

**版本 1.0.0** · PDF · EPUB · Markdown · TXT

---

## 概述

**AiReader** 是一款面向深度阅读的桌面 AI 助手。支持 PDF、EPUB、Markdown 和 TXT 格式。核心理念：**选中文字即可翻译、解释，并将结果沉淀为笔记**。AI 推理完全在本地运行，你的文档永远不会离开你的电脑。

## 核心功能

| 功能 | 说明 |
|:---|:---|
| 📖 多格式阅读 | PDF / EPUB / Markdown / TXT，阅读进度自动保存 |
| 🤖 本地 AI 推理 | 内置 llama.cpp，零配置开箱即用，自动适配硬件 |
| 🌐 选中即译 | 直译 / 意译 / 白话解释，复杂长句自动拆解 |
| 📝 文法解释 | 拆解句子结构、词汇用法 |
| 💬 上下文对话 | 围绕文档内容自由对话 |
| 📒 智能笔记 | AI 生成候选笔记，人工确认后持久化存储 |
| 🧠 深度思考 | Qwen3 真正的思考模式 |
| 📚 离线词典 | ECDICT + CC-CEDICT 词典，中英互译，选词即查 |
| 🌐 多种后端 | 也支持 Ollama、OpenAI 兼容 API |

---

## 界面布局

```
┌──────────────────────────────────────────────────────────────────────┐
│  ☰  文档标题                                     🌓   AI   ⚙        │
├────────────┬─────────────────────────────────┬───────────────────────┤
│            │                                 │                       │
│   侧边栏   │                                 │      AI 助手          │
│            │                                 │                       │
│  🅰 AiReader │       阅读区域                  │  ┌──┬──┬──┬──┐      │
│            │                                 │  │译│释│聊│记│      │
│  📂 导入    │       📖 PDF / EPUB / MD / TXT   │  ├──┴──┴──┴──┤      │
│            │                                 │  │             │      │
│  📄 论文    │                                 │  │  选中文本后  │      │
│  📘 小说    │                                 │  │  自动翻译    │      │
│  📝 笔记    │                                 │  │             │      │
│            │                                 │  │  翻译结果    │      │
│            │    ◀ ▶  ➖ 100% ➕  1/42  🌓     │  │  显示区域    │      │
│ ─────────  │    ↑ 浮动工具栏                   │  ├─────────────┤      │
│ 文档库     │                                 │  │ 💬 输入...  ➤│      │
│ 设置       │                                 │  └─────────────┘      │
├────────────┴─────────────────────────────────┴───────────────────────┤
│              所有面板分隔线均可拖动调节宽度                             │
└──────────────────────────────────────────────────────────────────────┘
```

### 面板说明

- **顶部栏** — 侧边栏切换、文档标题、主题切换、AI 面板切换、设置入口
- **侧边栏** — AiReader Logo（点击返回欢迎页）、导入文档按钮、文档列表、底部快捷操作
- **阅读区域** — 文档内容展示，支持目录侧栏、文本选择
- **AI 面板** — 翻译/文法/对话/笔记四个 Tab，支持模型切换和深度思考
- **浮动工具栏** — 目录切换、页码导航、缩放控制、阅读模式、文档主题

---

## 首次启动引导

首次启动应用时会自动进入引导向导，分三步：

1. **语言选择** — 选择中文或 English
2. **存储路径** — 设置文档库目录和 AI 模型目录（可使用默认值）
3. **AI 配置** — 一键配置内置 AI：
   - 硬件检测 → 枚举计算后端（CUDA / Vulkan / Metal / CPU）
   - 多引擎性能测试 → 自动选择最快后端
   - 展示模型列表 → 你自选 → 下载 → 启动
   - 也可配置 Ollama 或 OpenAI 兼容 API

引导完成后不会再次弹出。后续可在设置中修改所有配置。

---

## 导入文档

| 方式 | 说明 |
|:---|:---|
| 📂 导入文档 | 选择一个或多个文件 |
| 📁 导入文件夹 | 选择文件夹，自动扫描所有支持的文件 |

导入时可选择：

- **导入副本**（推荐）— 复制文件到应用数据目录，移动/删除原文件不影响阅读
- **直接打开** — 直接读取原文件路径，文件被移动或删除后将无法打开

支持格式：`.pdf` `.epub` `.md` `.txt`

---

## 阅读文档

**PDF 阅读器** — 连续滚动，缩放控制，页码导航，文本选择自动打开 AI，内部链接跳转，独立文档主题。

**EPUB 阅读器** — 翻页/滚动模式切换，缩放，独立文档主题，目录章节高亮跟踪。

**Markdown 阅读器** — 渲染 Markdown 格式，支持标题、列表、代码块、表格、图片等。

**TXT 阅读器** — 纯文本显示，自动换行。

---

## 目录导航

PDF 和 EPUB 支持目录侧栏，两种打开方式：

1. 阅读区域左侧边缘滑条 `>`
2. 浮动工具栏最左侧的目录按钮

支持多级嵌套、点击跳转、当前位置高亮、宽度可调。

---

## AI 助手

**打开方式：** 点击顶部栏 AI 按钮，或选中文本自动打开。

### 翻译

| 模式 | 说明 |
|:---|:---|
| 意译 | 自然流畅的翻译 |
| 直译 | 逐词逐句对照翻译 |
| 白话 | 用最简单的语言解释 |

自动检测语言方向：中文→英文 或 英文→中文。

### 文法解释

拆解选中文本的语法结构、词汇用法，帮助深入理解。

### 对话

- **围绕上下文** — 选中文本后，AI 自动锁定为上下文，可针对这段文本追问
- **Enter** 发送，**Shift+Enter** 换行
- 对话历史按文档持久化保存
- 可选中多条消息保存为笔记

### 笔记

- 翻译/解释结果一键保存
- 笔记与文档关联，支持导出 Markdown

### 深度思考

- **开启**（琥珀色）— AI 先思考再回答，质量更高
- **关闭** — AI 直接回答，速度更快

内置 Qwen3 模型支持**真正关闭**思考（不做内部推理，更快更省资源），与 Ollama 的软关闭不同。

---

## 词典弹窗

**双击**文档中的单词弹出词典窗口。

- **ECDICT** — 英语单词 → 中文释义（音标、词性、解释）
- **CC-CEDICT** — 中文词汇 → 英文释义（拼音、词性、解释）
- 可在设置中独立开关每个方向

---

## 设置

所有设置修改即时生效，无需手动保存。

### 通用

| 设置项 | 说明 |
|:---|:---|
| 界面语言 | 中文 / English |
| 离线词典 | ECDICT（英→中）、CC-CEDICT（中→英）独立开关 |
| 文档库目录 | 自定义导入副本的存储路径 |
| 模型存储目录 | AI 模型文件存放位置，修改时可迁移旧文件 |

### AI

| 提供方 | 说明 |
|:---|:---|
| 🖥 内置本地 | 一键配置本地 Qwen3 模型，支持从下拉列表直接管理 |
| 🦙 Ollama | 连接本地 Ollama 服务 |
| 🌐 OpenAI Compatible | 连接任何 OpenAI 兼容 API |

**简易模式**（一键配置）和**高级模式**（手动选型、GPU 配置）。

**智能分级策略** — 三层自适应：

1. **硬件探测** — 枚举后端（CUDA / Vulkan / Metal / CPU）
2. **多引擎测试** — llama-bench 逐个测试，选最快
3. **模型选择** — 推荐等级，用户从完整列表自选

| 基准测试 | 模型 | 大小 |
|:---|:---|:---|
| ≥ 420 tok/s | Qwen3-32B | ~19 GB |
| 185–419 tok/s | Qwen3-14B | ~9 GB |
| 100–184 tok/s | Qwen3-8B | ~5 GB |
| 50–99 tok/s | Qwen3-4B | ~2.7 GB |
| 20–49 tok/s | Qwen3-1.7B | ~1.2 GB |
| < 20 tok/s | Qwen3-0.6B | ~0.5 GB |

所有模型均为 Q4_K_M 量化。集成显卡自动回退 CPU 模式。

### 存储

- 文档缓存管理（LRU 策略）
- 重置应用（清空所有数据回到初始状态）

---

## 快捷键

| 快捷键 | 功能 |
|:---|:---|
| 双击单词 | 词典弹窗 |
| 选中文本 | 自动打开 AI 面板 |
| Enter（对话框）| 发送消息 |
| Shift + Enter | 换行 |

---

## 常见问题

**Q: 模型下载很慢？**
系统会自动探测最快的镜像源（国内 ModelScope / 海外 HuggingFace）。如果仍然慢，可在高级模式中点击 **链接** 复制下载地址，用其他下载工具下载后点击 **导入** 导入。

**Q: 支持哪些平台和 GPU？**
Windows x64、macOS (arm64/x64)、Ubuntu x64。GPU 加速：NVIDIA (CUDA 12.4/13.1)、AMD/Intel (Vulkan)、Apple Silicon (Metal)、CPU 模式（所有电脑可用）。

**Q: 集成显卡为什么不用 GPU 加速？**
集成显卡显存通常 < 2GB，实测比纯 CPU 更慢。系统会自动检测并回退到 CPU 模式。

**Q: 模型太慢怎么办？**
简易模式下有「降级到更小模型」按钮；或在高级模式中手动选择更小的模型。

**Q: 如何更新？**
下载新版安装包直接运行即可，自动覆盖旧版本。文档、笔记、模型和设置均会保留。

---

*AiReader — Read. Select. Translate. Save.*
