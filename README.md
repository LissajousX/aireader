<div align="center">

# âœ¨ Aireader

**From Documents to Knowledge â€” Powered by Your Own GPU**

**ä»æ–‡æ¡£åˆ°çŸ¥è¯† â€”â€” ç”¨ä½ è‡ªå·±çš„ç®—åŠ›é©±åŠ¨ AI é˜…è¯»**

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Tauri 2.0](https://img.shields.io/badge/Tauri-2.0-orange)](https://tauri.app)
[![llama.cpp](https://img.shields.io/badge/llama.cpp-built--in-green)](https://github.com/ggerganov/llama.cpp)

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

</div>

---

<a id="ä¸­æ–‡"></a>

## ğŸ‡¨ğŸ‡³ ä¸­æ–‡

### ä¸ºä»€ä¹ˆé€‰æ‹© Aireaderï¼Ÿ

> ä½ çš„æ–‡æ¡£ä¸ä¼šä¸Šä¼ åˆ°ä»»ä½•äº‘ç«¯ã€‚AI æ¨ç†å®Œå…¨åœ¨æœ¬åœ°è¿è¡Œã€‚

å¤§å¤šæ•° AI é˜…è¯»å·¥å…·éœ€è¦æŠŠä½ çš„æ–‡æ¡£å‘é€åˆ°äº‘ç«¯ï¼ŒAireader ä¸åŒï¼š

- **ğŸ”’ å®Œå…¨ç¦»çº¿** â€” å†…ç½® llama.cpp æ¨ç†å¼•æ“ï¼ŒAI åœ¨ä½ çš„ç”µè„‘ä¸Šè¿è¡Œï¼Œæ•°æ®æ°¸è¿œä¸å‡ºæœ¬æœº
- **âš¡ æ™ºèƒ½ç¡¬ä»¶é€‚é…** â€” è‡ªåŠ¨æ£€æµ‹ GPUï¼Œæ”¯æŒ CUDA / Vulkan / CPUï¼›å†…ç½® llama-bench åŸºå‡†æµ‹è¯•ï¼Œå®æµ‹æ€§èƒ½åç²¾å‡†åŒ¹é…æœ€æµç•…çš„æ¨¡å‹
- **ğŸ“– ä¸“æ³¨é˜…è¯»ä½“éªŒ** â€” ä¸æ˜¯åˆä¸€ä¸ªèŠå¤©å·¥å…·ï¼Œè€Œæ˜¯çœŸæ­£ä¸ºæ·±åº¦é˜…è¯»è®¾è®¡çš„ AI åŠ©æ‰‹

### æˆªå›¾é¢„è§ˆ

![ä¸»ç•Œé¢](screenshots/main-interface.png)

<details>
<summary>æ›´å¤šæˆªå›¾</summary>

![é€‰ä¸­å³è¯‘](screenshots/select-translate.png)

![AI å¯¹è¯](screenshots/ai-chat.png)

![ä¸€é”®é…ç½®](screenshots/quick-setup.png)

![æš—è‰²ä¸»é¢˜](screenshots/dark-theme.png)

![è¯å…¸å¼¹çª—](screenshots/dictionary-popup.png)

</details>

### æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ | æè¿° |
|:---|:---|
| ğŸ“„ **å¤šæ ¼å¼æ”¯æŒ** | PDF Â· EPUB Â· Markdown Â· TXTï¼Œé˜…è¯»è¿›åº¦è‡ªåŠ¨ä¿å­˜ |
| ğŸ¤– **æœ¬åœ° AI æ¨ç†** | å†…ç½® llama.cppï¼Œé›¶é…ç½®å¼€ç®±å³ç”¨ï¼Œllama-bench åŸºå‡†æµ‹è¯•ç²¾å‡†åŒ¹é…ç¡¬ä»¶ |
| ğŸŒ **å¤šç§ AI åç«¯** | ä¹Ÿæ”¯æŒ Ollamaã€OpenAI å…¼å®¹ APIï¼Œè‡ªç”±é€‰æ‹© |
| ğŸ”¤ **é€‰ä¸­å³ç¿»è¯‘** | ç›´è¯‘ / æ„è¯‘ / ç™½è¯è§£é‡Šï¼Œå¤æ‚é•¿å¥è‡ªåŠ¨æ‹†è§£ |
| ğŸ“š **ç¦»çº¿è¯å…¸** | å†…ç½® ECDICT + CC-CEDICT è¯å…¸ï¼Œä¸­è‹±äº’è¯‘ï¼Œé€‰è¯å³æŸ¥ï¼Œæ— éœ€è”ç½‘ |
| ğŸ“ **æ™ºèƒ½ç¬”è®°** | AI ç”Ÿæˆå€™é€‰ç¬”è®°ï¼Œäººå·¥ç¡®è®¤åæŒä¹…åŒ–å­˜å‚¨ (SQLite) |
| ğŸ’¬ **ä¸Šä¸‹æ–‡å¯¹è¯** | å¯ä»¥å°±å½“å‰é˜…è¯»å†…å®¹ä¸ AI å¤šè½®å¯¹è¯ï¼Œæ”¯æŒæ·±åº¦æ€è€ƒ |
| ğŸ“ **æ–‡æ¡£åº“ç®¡ç†** | å‰¯æœ¬å¯¼å…¥ / é“¾æ¥å¯¼å…¥ï¼Œè‡ªå®šä¹‰å­˜å‚¨ç›®å½• |
| ğŸŒ“ **æš—è‰² / äº®è‰²ä¸»é¢˜** | è·Ÿéšç³»ç»Ÿæˆ–æ‰‹åŠ¨åˆ‡æ¢ï¼Œæ–‡æ¡£åŒºåŸŸå¯ç‹¬ç«‹æ§åˆ¶ |
| ğŸŒ **ä¸­è‹±åŒè¯­ç•Œé¢** | è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿè¯­è¨€ |

### æ™ºèƒ½ç¡¬ä»¶é€‚é…

Aireader é‡‡ç”¨ **ä¸‰å±‚è‡ªé€‚åº”ç­–ç•¥** è‡ªåŠ¨ä¸ºä½ çš„ç¡¬ä»¶åŒ¹é…æœ€æµç•…çš„æ¨¡å‹ï¼š

1. **ç¡¬ä»¶æ¢æµ‹** â€” æ£€æµ‹ GPU ç±»å‹ä¸æ˜¾å­˜ï¼Œé€‰æ‹©æœ€ä½³è®¡ç®—æ¨¡å¼ï¼ˆCUDA / Vulkan / CPUï¼‰
2. **èµ„æºåˆç­›** â€” æ ¹æ® CPU æ ¸å¿ƒæ•°ã€å†…å­˜ã€æ˜¾å­˜å¿«é€Ÿé¢„ä¼°æ¨¡å‹çº§åˆ«
3. **åŸºå‡†æµ‹è¯•** â€” ç”¨ llama-bench å®æµ‹æ¨ç†é€Ÿåº¦ (tok/s)ï¼Œç²¾ç¡®é€‰æ‹©æœ€æµç•…çš„æ¨¡å‹

é›†æˆæ˜¾å¡ï¼ˆIntel UHD/HD/Irisï¼Œæ˜¾å­˜ < 2GBï¼‰è‡ªåŠ¨å›é€€åˆ° CPU æ¨¡å¼ä»¥è·å¾—æ›´å¥½æ€§èƒ½ã€‚

### å¿«é€Ÿå¼€å§‹

```bash
# å®‰è£…ä¾èµ–
npm install

# å¼€å‘æ¨¡å¼
npm run tauri dev

# æ„å»ºå‘å¸ƒç‰ˆ
npm run tauri build
```

### ä½¿ç”¨æ–¹å¼

1. æ‰“å¼€åº”ç”¨ â†’ è®¾ç½® â†’ **ä¸€é”®é…ç½®å†…ç½® AI**ï¼ˆè‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶ã€åŸºå‡†æµ‹è¯•ã€ä¸‹è½½æ¨¡å‹ï¼‰
2. æ‰“å¼€æ–‡æ¡£ï¼Œé€‰ä¸­è‹±æ–‡æ–‡æœ¬
3. AI é¢æ¿è‡ªåŠ¨å¼¹å‡º â†’ ç¿»è¯‘ / è§£é‡Š / å¯¹è¯
4. æœ‰ä»·å€¼çš„å†…å®¹ â†’ ä¿å­˜ä¸ºç¬”è®°

ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼š[USER_GUIDE.md](USER_GUIDE.md)

---

<a id="english"></a>

## ğŸ‡¬ğŸ‡§ English

### Why Aireader?

> Your documents never leave your machine. AI inference runs 100% locally.

Most AI reading tools send your documents to the cloud. Aireader is different:

- **ğŸ”’ Fully Offline** â€” Built-in llama.cpp engine, AI runs on your computer, data never leaves your machine
- **âš¡ Smart Hardware Adaptation** â€” Auto-detects GPU, supports CUDA / Vulkan / CPU; uses llama-bench to measure actual performance and precisely match the smoothest model
- **ğŸ“– Reading-First Design** â€” Not another chatbot, but a true AI assistant built for deep reading

### Screenshots

![Main Interface](screenshots/main-interface.png)

<details>
<summary>More Screenshots</summary>

![Select to Translate](screenshots/select-translate.png)

![AI Chat](screenshots/ai-chat.png)

![Quick Setup](screenshots/quick-setup.png)

![Dark Theme](screenshots/dark-theme.png)

![Dictionary Popup](screenshots/dictionary-popup.png)

</details>

### Key Features

| Feature | Description |
|:---|:---|
| ğŸ“„ **Multi-Format** | PDF Â· EPUB Â· Markdown Â· TXT with auto-saved reading progress |
| ğŸ¤– **Local AI Inference** | Built-in llama.cpp, zero-config, llama-bench benchmark for precise hardware matching |
| ğŸŒ **Multiple AI Backends** | Also supports Ollama, OpenAI-compatible APIs |
| ğŸ”¤ **Select to Translate** | Literal / free / plain-language translation, complex sentence breakdown |
| ğŸ“š **Offline Dictionary** | Built-in ECDICT + CC-CEDICT dictionaries, bidirectional Chinese-English lookup, no internet needed |
| ğŸ“ **Smart Notes** | AI-generated draft notes, human-confirmed persistent storage (SQLite) |
| ğŸ’¬ **Contextual Chat** | Multi-turn conversation about reading content, with deep thinking support |
| ğŸ“ **Document Library** | Copy or link import, custom storage directory |
| ğŸŒ“ **Dark / Light Theme** | Follow system or manual toggle, independent document area control |
| ğŸŒ **Bilingual UI** | Chinese & English, auto-detected |

### Smart Hardware Adaptation

Aireader uses a **3-layer adaptive strategy** to automatically match the smoothest model for your hardware:

1. **Hardware Detection** â€” Detect GPU type & VRAM, select optimal compute mode (CUDA / Vulkan / CPU)
2. **Resource Pre-filter** â€” Quick estimate based on CPU cores, RAM, and VRAM
3. **Benchmark** â€” Run llama-bench to measure actual inference speed (tok/s), precisely select the smoothest model

Integrated GPUs (Intel UHD/HD/Iris, VRAM < 2GB) automatically fall back to CPU mode for better performance.

### Quick Start

```bash
# Install dependencies
npm install

# Development mode
npm run tauri dev

# Build for production
npm run tauri build
```

### How to Use

1. Open app â†’ Settings â†’ **One-Click AI Setup** (auto-detects hardware, benchmarks, downloads model)
2. Open a document, select English text
3. AI panel appears â†’ Translate / Explain / Chat
4. Save valuable content as notes

ğŸ“– Full user guide: [USER_GUIDE.md](USER_GUIDE.md)

---

## Tech Stack

| Layer | Technology |
|:---|:---|
| Frontend | React 18 Â· TypeScript Â· TailwindCSS Â· Zustand |
| Desktop | Tauri 2.0 (Rust) |
| AI Engine | llama.cpp Â· llama-bench (built-in) Â· Ollama Â· OpenAI-compatible API |
| Rendering | react-pdf / pdf.js Â· epub.js Â· react-markdown |
| Storage | SQLite (rusqlite) Â· localStorage |
| Dictionary | ECDICT (CSV) Â· CC-CEDICT |

## Project Structure

```
aireader/
â”œâ”€â”€ src/                        # React frontend
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ai/                 # AI panel & contextual chat
â”‚   â”‚   â”œâ”€â”€ help/               # Help modal
â”‚   â”‚   â”œâ”€â”€ layout/             # Sidebar, welcome, document library
â”‚   â”‚   â”œâ”€â”€ notes/              # Notes panel
â”‚   â”‚   â”œâ”€â”€ reader/             # PDF / EPUB / TXT / MD readers
â”‚   â”‚   â”œâ”€â”€ settings/           # Settings modal
â”‚   â”‚   â””â”€â”€ ui/                 # Shared UI & dictionary popup
â”‚   â”œâ”€â”€ i18n/                   # Internationalization
â”‚   â”œâ”€â”€ services/               # Ollama API & streaming
â”‚   â”œâ”€â”€ stores/                 # Zustand state management
â”‚   â””â”€â”€ types/                  # TypeScript type definitions
â”œâ”€â”€ src-tauri/                  # Rust backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib.rs              # Tauri commands & file management
â”‚   â”‚   â”œâ”€â”€ builtin_llm.rs      # llama.cpp integration & model management
â”‚   â”‚   â”œâ”€â”€ database.rs         # SQLite note storage
â”‚   â”‚   â”œâ”€â”€ dictionary.rs       # ECDICT / CC-CEDICT dictionary
â”‚   â”‚   â”œâ”€â”€ epub.rs             # EPUB extraction
â”‚   â”‚   â””â”€â”€ ollama.rs           # Ollama proxy
â”‚   â”œâ”€â”€ resources/              # Dictionaries & sample documents
â”‚   â””â”€â”€ Cargo.toml
â”œâ”€â”€ screenshots/                # Application screenshots
â”œâ”€â”€ USER_GUIDE.md               # User guide (bilingual)
â””â”€â”€ package.json
```

## Development Requirements

- Node.js 18+
- Rust 1.70+
- Optional: Ollama (for Ollama mode)

## License

[MIT](LICENSE) Â© xujiayu

